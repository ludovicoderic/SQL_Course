{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/select-from-where).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"### SELECT ... FROM\nThe most basic SQL query selects a single column from a single table. To do this,\n\n- specify the column you want after the word SELECT, and then\n- specify the table after the word FROM.\n\nFor instance, to select the Name column (from the pets table in the pet_records database in the bigquery-public-data project), our query would appear as follows:\n\nIn case it's useful to see an example query, here's some code from the tutorial:\n\n![](https://i.imgur.com/c3GxYRt.png)\n\n### WHERE\nBigQuery datasets are large, so you'll usually want to return only the rows meeting specific conditions. You can do this using the WHERE clause.\n\nThe query below returns the entries from the Name column that are in rows where the Animal column has the text 'Cat'.\n\n![](https://i.imgur.com/HJOT8Kb.png)","metadata":{}},{"cell_type":"markdown","source":"### More queries\nIf you want multiple columns, you can select them with a comma between the names:\n```\nquery = \"\"\"\n        SELECT city, country\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"\n```\n\n\nYou can select all columns with a * like this:     \n```\nquery = \"\"\"\n        SELECT *\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"\n```\n","metadata":{}},{"cell_type":"markdown","source":"\n### Working with big datasets\nBigQuery datasets can be huge. We allow you to do a lot of computation for free, but everyone has some limit.\n\n**Each Kaggle user can scan 5TB every 30 days for free. Once you hit that limit, you'll have to wait for it to reset.**\n\nThe biggest dataset currently on Kaggle is 3TB, so you can go through your 30-day limit in a couple queries if you aren't careful.\n\nDon't worry though: we'll teach you how to avoid scanning too much data at once, so that you don't run over your limit.\n\nTo begin,you can estimate the size of any query before running it. Here is an example using the (very large!) Hacker News dataset. To see how much data a query will scan, we create a QueryJobConfig object and set the dry_run parameter to True.\n\n\nQuery to get the score column from every row where the type column has value \"job\"\n```\nquery = \"\"\"\n        SELECT score, title\n        FROM `bigquery-public-data.hacker_news.full`\n        WHERE type = \"job\" \n        \"\"\"\n```\nCreate a QueryJobConfig object to estimate size of query without running it\n\n```\ndry_run_config = bigquery.QueryJobConfig(dry_run=True)\n```\n\nAPI request - dry run query to estimate costs\n\n```\ndry_run_query_job = client.query(query, job_config=dry_run_config)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))\n```\n> This query will process 494391991 bytes.\n\nYou can also specify a parameter when running the query to limit how much data you are willing to scan. Here's an example with a low limit.\n\nOnly run the query if it's less than 1 MB\n```\nONE_MB = 1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n```\n\nSet up the query (will only run if it's less than 1 MB)\n```\nsafe_query_job = client.query(query, job_config=safe_config)\n```\n\nAPI request - try to run the query, and return a pandas DataFrame\n```\nsafe_query_job.to_dataframe()\n```","metadata":{}},{"cell_type":"markdown","source":"### Q&A: Notes on formatting\n\nThe formatting of the SQL query might feel unfamiliar. If you have any questions, you can ask in the comments section at the bottom of this page. Here are answers to two common questions:\n\nQuestion: What's up with the triple quotation marks (\"\"\")?\nAnswer: These tell Python that everything inside them is a single string, even though we have line breaks in it. The line breaks aren't necessary, but they make it easier to read your query.\n\nQuestion: Do you need to capitalize SELECT and FROM?\nAnswer: No, SQL doesn't care about capitalization. However, it's customary to capitalize your SQL commands, and it makes your queries a bit easier to read.","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nTry writing some **SELECT** statements of your own to explore a large dataset of air pollution measurements.\n\nRun the cell below to set up the feedback system.","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex2 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:55:42.964253Z","iopub.execute_input":"2022-10-19T16:55:42.964733Z","iopub.status.idle":"2022-10-19T16:56:25.922804Z","shell.execute_reply.started":"2022-10-19T16:55:42.964635Z","shell.execute_reply":"2022-10-19T16:56:25.921410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code cell below fetches the `global_air_quality` table from the `openaq` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"openaq\" dataset\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"global_air_quality\" table\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"global_air_quality\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T16:56:25.925238Z","iopub.execute_input":"2022-10-19T16:56:25.926023Z","iopub.status.idle":"2022-10-19T16:56:27.381361Z","shell.execute_reply.started":"2022-10-19T16:56:25.925973Z","shell.execute_reply":"2022-10-19T16:56:27.380130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Units of measurement\n\nWhich countries have reported pollution levels in units of \"ppm\"?  In the code cell below, set `first_query` to an SQL query that pulls the appropriate entries from the `country` column.","metadata":{}},{"cell_type":"code","source":"# Query to select countries with units of \"ppm\"\nfirst_query = \"\"\"\n              SELECT country\n              FROM `bigquery-public-data.openaq.global_air_quality`\n              WHERE unit = \"ppm\"\n              \"\"\"\n\n# Or to get each country just once, you could use\nfirst_query = \"\"\"\n              SELECT DISTINCT country\n              FROM `bigquery-public-data.openaq.global_air_quality`\n              WHERE unit = \"ppm\"\n              \"\"\"\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nfirst_query_job = client.query(first_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nfirst_results = first_query_job.to_dataframe()\n\n# View size of results\nprint(len(first_results))\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T17:06:57.718308Z","iopub.execute_input":"2022-10-19T17:06:57.718717Z","iopub.status.idle":"2022-10-19T17:06:58.990999Z","shell.execute_reply.started":"2022-10-19T17:06:57.718685Z","shell.execute_reply":"2022-10-19T17:06:58.989888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some countries showed up many times in the results. To get each country only once you can run `SELECT DISTINCT country ...`. The DISTINCT keyword ensures each column shows up once, which you'll want in some cases.","metadata":{}},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"# q_1.solution()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T17:08:12.172679Z","iopub.execute_input":"2022-10-19T17:08:12.173131Z","iopub.status.idle":"2022-10-19T17:08:12.178444Z","shell.execute_reply.started":"2022-10-19T17:08:12.173085Z","shell.execute_reply":"2022-10-19T17:08:12.177146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) High air quality\n\nWhich pollution levels were reported to be exactly 0?  \n- Set `zero_pollution_query` to select **all columns** of the rows where the `value` column is 0.\n- Set `zero_pollution_results` to a pandas DataFrame containing the query results.","metadata":{}},{"cell_type":"code","source":"# Query to select all columns where pollution levels are exactly 0\nzero_pollution_query = \"\"\"\n                       SELECT *\n                       FROM `bigquery-public-data.openaq.global_air_quality`\n                       WHERE value = 0\n                       \"\"\"# Your code goes here\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(zero_pollution_query, job_config=safe_config)\n\n# API request - run the query and return a pandas DataFrame\nzero_pollution_results = query_job.to_dataframe() # Your code goes here\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T17:27:18.136895Z","iopub.execute_input":"2022-10-19T17:27:18.137350Z","iopub.status.idle":"2022-10-19T17:27:43.231001Z","shell.execute_reply.started":"2022-10-19T17:27:18.137315Z","shell.execute_reply":"2022-10-19T17:27:43.229747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"display(zero_pollution_results.head())","metadata":{"execution":{"iopub.status.busy":"2022-10-19T17:27:53.056552Z","iopub.execute_input":"2022-10-19T17:27:53.056932Z","iopub.status.idle":"2022-10-19T17:27:53.079367Z","shell.execute_reply.started":"2022-10-19T17:27:53.056902Z","shell.execute_reply":"2022-10-19T17:27:53.078093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# q_2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T17:28:26.620190Z","iopub.execute_input":"2022-10-19T17:28:26.620730Z","iopub.status.idle":"2022-10-19T17:28:26.627614Z","shell.execute_reply.started":"2022-10-19T17:28:26.620682Z","shell.execute_reply":"2022-10-19T17:28:26.625808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That query wasn't too complicated, and it got the data you want. But these **SELECT** queries don't organizing data in a way that answers the most interesting questions. For that, we'll need the **GROUP BY** command. \n\nIf you know how to use [`groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) in pandas, this is similar. But BigQuery works quickly with far larger datasets.\n\nFortunately, that's next.","metadata":{}},{"cell_type":"markdown","source":"# Keep going\n**[GROUP BY](https://www.kaggle.com/dansbecker/group-by-having-count)** clauses and their extensions give you the power to pull interesting statistics out of data, rather than receiving it in just its raw format.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}